{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.svm.libsvm import cross_validation\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "postcodes2017 = pd.read_excel(\"postcodes2017.xlsx\")\n",
    "\n",
    "# Adjust missing data for most recent homes\n",
    "for i in postcodes2017.index:\n",
    "    if postcodes2017.loc[i, 'WON_1524,N,10,0'] == -99997:\n",
    "        postcodes2017.loc[i, 'WON_1524,N,10,0'] = 0\n",
    "\n",
    "# Select relevant columns        \n",
    "columns = ['PC4,N,5,0', 'INWONER,N,10,0', 'MAN,N,10,0', 'VROUW,N,10,0',\n",
    "       'INW_014,N,10,0', 'INW_1524,N,10,0', 'INW_2544,N,10,0',\n",
    "       'INW_4564,N,10,0', 'INW_65PL,N,10,0', 'GEBOORTE,N,10,0',\n",
    "       'P_NL_ACHTG,N,10,0', 'P_WE_MIG_A,N,10,0', 'P_NW_MIG_A,N,10,0',\n",
    "       'AANTAL_HH,N,10,0', 'TOTHH_EENP,N,10,0', 'TOTHH_MPZK,N,10,0',\n",
    "       'HH_EENOUD,N,10,0', 'HH_TWEEOUD,N,10,0', 'GEM_HH_GR,N,19,11',\n",
    "       'WONING,N,10,0', 'WONVOOR45,N,10,0', 'WON_4564,N,10,0',\n",
    "       'WON_6574,N,10,0', 'WON_7584,N,10,0', 'WON_8594,N,10,0',\n",
    "       'WON_9504,N,10,0', 'WON_0514,N,10,0', 'WON_1524,N,10,0',\n",
    "       'WON_MRGEZ,N,10,0', 'P_HUURWON,N,10,0', 'P_KOOPWON,N,10,0',\n",
    "       'WON_HCORP,N,10,0', 'WON_NBEW,N,10,0',\n",
    "       'G_GAS_WON,N,10,0', 'G_ELEK_WON,N,10,0', 'UITKMINAOW,N,10,0', 'STED,N,10,0']\n",
    "\n",
    "postcodes2017 = postcodes2017[columns]\n",
    "\n",
    "# Set index to postal code\n",
    "postcodes2017 = postcodes2017.set_index(\"PC4,N,5,0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data backup\n",
    "data = postcodes2017.copy()\n",
    "\n",
    "# Change missing data to NaN\n",
    "for i in data.index:\n",
    "    for j in data.columns:\n",
    "        if data.loc[i, j] == -99997:\n",
    "            data.loc[i,j] = float('NaN')\n",
    "\n",
    "# Create percentage columns\n",
    "data['PERC_EENP'] = data['TOTHH_EENP,N,10,0'] / data['AANTAL_HH,N,10,0'] * 100\n",
    "data['PERC_MPZK'] = data['TOTHH_MPZK,N,10,0'] / data['AANTAL_HH,N,10,0'] * 100\n",
    "data['PERC_EENOUD'] = data['HH_EENOUD,N,10,0'] / data['AANTAL_HH,N,10,0'] * 100\n",
    "data['PERC_TWEEOUD'] = data['HH_TWEEOUD,N,10,0'] / data['AANTAL_HH,N,10,0'] * 100\n",
    "\n",
    "data['PERC_MAN'] = data['MAN,N,10,0'] / data['INWONER,N,10,0'] * 100\n",
    "data['PERC_VROUW'] = 100 - data['PERC_MAN']\n",
    "data['PERC_014'] = data['INW_014,N,10,0'] / data['INWONER,N,10,0'] * 100\n",
    "data['PERC_1524'] = data['INW_1524,N,10,0'] / data['INWONER,N,10,0'] * 100\n",
    "data['PERC_2544'] = data['INW_2544,N,10,0'] / data['INWONER,N,10,0'] * 100\n",
    "data['PERC_4564'] = data['INW_4564,N,10,0'] / data['INWONER,N,10,0'] * 100\n",
    "data['PERC_65PL'] = data['INW_65PL,N,10,0'] / data['INWONER,N,10,0'] * 100\n",
    "\n",
    "data['TOTAAL_WON'] = data['WONVOOR45,N,10,0'] + data['WON_4564,N,10,0'] + data['WON_6574,N,10,0'] + data['WON_7584,N,10,0'] + data['WON_8594,N,10,0'] + data['WON_9504,N,10,0'] + data['WON_0514,N,10,0'] + data['WON_1524,N,10,0']\n",
    "\n",
    "data['PERC_WON_045'] = data['WONVOOR45,N,10,0'] / data['TOTAAL_WON'] * 100\n",
    "data['PERC_WON_4564'] = data['WON_4564,N,10,0'] / data['TOTAAL_WON'] * 100\n",
    "data['PERC_WON_6574'] = data['WON_6574,N,10,0'] / data['TOTAAL_WON'] * 100\n",
    "data['PERC_WON_7584'] = data['WON_7584,N,10,0'] / data['TOTAAL_WON'] * 100\n",
    "data['PERC_WON_8594'] = data['WON_8594,N,10,0'] / data['TOTAAL_WON'] * 100\n",
    "data['PERC_WON_9504'] = data['WON_9504,N,10,0'] / data['TOTAAL_WON'] * 100\n",
    "data['PERC_WON_0514'] = data['WON_0514,N,10,0'] / data['TOTAAL_WON'] * 100\n",
    "data['PERC_WON_1524'] = data['WON_1524,N,10,0'] / data['TOTAAL_WON'] * 100\n",
    "\n",
    "# Select relevant columns\n",
    "columns = ['PERC_MAN', 'PERC_014', 'PERC_1524', 'PERC_2544',\n",
    "       'PERC_4564', 'PERC_65PL',\n",
    "       'P_NL_ACHTG,N,10,0', 'P_WE_MIG_A,N,10,0', 'P_NW_MIG_A,N,10,0', 'PERC_EENP', 'PERC_MPZK',\n",
    "       'PERC_EENOUD', 'PERC_TWEEOUD', 'PERC_WON_045', 'PERC_WON_4564',\n",
    "       'PERC_WON_6574', 'PERC_WON_7584', 'PERC_WON_8594',\n",
    "       'PERC_WON_9504', 'PERC_WON_0514', 'PERC_WON_1524', 'G_GAS_WON,N,10,0', 'G_ELEK_WON,N,10,0', 'WON_MRGEZ,N,10,0', 'STED,N,10,0', 'GEM_HH_GR,N,19,11']\n",
    "\n",
    "data = data[columns]\n",
    "\n",
    "# Remove missing data\n",
    "data = data.dropna()\n",
    "\n",
    "# Create data backup\n",
    "data2 = data.copy()\n",
    "\n",
    "# Scale data\n",
    "X = X.values\n",
    "min_max_scaler = preprocessing.StandardScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(X)\n",
    "X = pd.DataFrame(x_scaled)\n",
    "X.columns = columns\n",
    "X.index = ind\n",
    "data = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse7(data, iv, lasso, energy, data2):\n",
    "    # This function runs an elastic net model for the data set. It takes parameters on whether to include\n",
    "    # interaction variables and what energy type to run the analysis for\n",
    "    \n",
    "    X = data.copy()\n",
    "    y = data2[energy]\n",
    "    \n",
    "    # Select relevant columns\n",
    "    columns = ['PERC_MAN', 'PERC_1524', 'PERC_2544',\n",
    "       'PERC_4564', 'PERC_65PL',\n",
    "       'P_NL_ACHTG,N,10,0', 'P_WE_MIG_A,N,10,0', 'PERC_MPZK',\n",
    "       'PERC_EENOUD', 'PERC_TWEEOUD', 'PERC_WON_4564',\n",
    "       'PERC_WON_6574', 'PERC_WON_7584', 'PERC_WON_8594',\n",
    "       'PERC_WON_9504', 'PERC_WON_0514', 'PERC_WON_1524',]\n",
    "    \n",
    "    X = X[columns]\n",
    "    \n",
    "    # Create interaction variables\n",
    "    if iv == 1:\n",
    "        vis = []\n",
    "        fish = []\n",
    "\n",
    "        for i in columns:\n",
    "            for j in columns:\n",
    "                if j not in fish:\n",
    "                    vis.append([i,j])\n",
    "            fish.append(i)\n",
    "            \n",
    "        columns2 = columns.copy()\n",
    "\n",
    "        for i in vis:\n",
    "            columns2.append(i)\n",
    "            \n",
    "        for i in columns2:\n",
    "            if len(i) == 2:\n",
    "                X[i[0] + ' x ' + i[1]] = X[i[0]] * X[i[1]]\n",
    "            \n",
    "#         X = X.iloc[:, 17:]\n",
    "    \n",
    "    # Manually create trainig and test split, due to bug in Scikit package\n",
    "\n",
    "    list1 = set(X.index)\n",
    "\n",
    "    train = sample(list1, int(0.7 * len(list1)))\n",
    "\n",
    "    X_train = X.loc[train, :]\n",
    "    y_train = y[train]\n",
    "\n",
    "    train = set(train)\n",
    "\n",
    "    test = list1 - train\n",
    "\n",
    "    X_test = X.loc[test, :]\n",
    "    test = list(test)\n",
    "    y_test = y[test]\n",
    "    \n",
    "    # Run elastic net for various lambda parameters\n",
    "    if True:\n",
    "        values = [0, 0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 20, 30]\n",
    "        scores = []\n",
    "        scores2 = []\n",
    "\n",
    "        if True:\n",
    "            for i in values:\n",
    "                #Lasso om variabelen te bepalen\n",
    "                clf = linear_model.ElasticNet(alpha=i, l1_ratio = lasso)\n",
    "\n",
    "                clf.fit(X_train,y_train)\n",
    "\n",
    "                preds = list(clf.predict(X_test))\n",
    "                trues = list(y_test)\n",
    "\n",
    "                errors = [a_i - b_i for a_i, b_i in zip(preds, trues)]\n",
    "\n",
    "                rmse = [math.sqrt(x**2) for x in errors]\n",
    "\n",
    "                scores.append(sum(rmse)/len(rmse))\n",
    "                \n",
    "                print(sum(abs(clf.coef_))/len(clf.coef_))\n",
    "                print(len(clf.coef_[clf.coef_ != 0]))\n",
    "        \n",
    "                # Manually calculate R-squared\n",
    "                coef = clf.coef_\n",
    "                p = numpy.poly1d(coef)\n",
    "                yhat = clf.predict(X_train)\n",
    "\n",
    "                ybar = numpy.sum(y_train)/len(y_train)          # or sum(y)/len(y)\n",
    "                ssreg = numpy.sum((yhat - ybar)**2)   # or sum([ (yihat - ybar)**2 for yihat in yhat])\n",
    "                sstot = numpy.sum((y_train - ybar)**2)    # or sum([ (yi - ybar)**2 for yi in y])\n",
    "                print(ssreg / sstot)\n",
    "        \n",
    "                print('--------------------------')\n",
    "            \n",
    "                coef = clf.coef_\n",
    "                \n",
    "                # Manually create the standard errors of the coefficients\n",
    "                MSE = np.mean((y_train - clf.predict(X_train).T)**2)\n",
    "                var_est = MSE * np.diag(np.linalg.pinv(np.dot(X_train.T,X_train)))\n",
    "                SE_est = np.sqrt(var_est)\n",
    "                \n",
    "                temp = pd.DataFrame()\n",
    "                temp['Coef'] = coef\n",
    "                \n",
    "                # Calculate t-values\n",
    "                tvalues = coef / SE_est\n",
    "                \n",
    "                # Calculate p-values\n",
    "                pvalues = []\n",
    "                for k in tvalues:\n",
    "                    pvalues.append(scipy.stats.t.sf(abs(k), df=0.7*len(data)-len(coef)))\n",
    "                    \n",
    "                temp['P-value'] = pvalues\n",
    "                \n",
    "                length = len(temp[(temp['Coef'] != 0) & (temp['P-value'] < 0.01)])\n",
    "            \n",
    "                scores2.append([i, sum(abs(clf.coef_)), sum(rmse)/len(rmse), length, ssreg / sstot])\n",
    "            \n",
    "            # Rerun the model for the best performing lambda parameter\n",
    "            max_value = min(scores)\n",
    "            max_index = scores.index(max_value)\n",
    "\n",
    "            clf = linear_model.ElasticNet(alpha=values[max_index], l1_ratio = lasso)\n",
    "\n",
    "            clf.fit(X_train,y_train)\n",
    "\n",
    "            coef = clf.coef_\n",
    "            \n",
    "            MSE = np.mean((y_train - clf.predict(X_train).T)**2)\n",
    "            var_est = MSE * np.diag(np.linalg.pinv(np.dot(X_train.T,X_train)))\n",
    "            SE_est = np.sqrt(var_est)\n",
    "            \n",
    "    return [coef, SE_est, X, scores2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef, se, X, scores2 = analyse7(data, 0, 0.3, 'G_GAS_WON,N,10,0', data2)\n",
    "tvalues = coef / se\n",
    "\n",
    "#find p-value\n",
    "pvalues = []\n",
    "for i in tvalues:\n",
    "    pvalues.append(scipy.stats.t.sf(abs(i), df=0.7*len(data)-len(coef)))\n",
    "\n",
    "results = pd.DataFrame(index=X.columns)\n",
    "\n",
    "results['Coefficient'] = coef\n",
    "results['Standard Error'] = se\n",
    "results['P-value'] = pvalues\n",
    "\n",
    "pd.DataFrame(scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse6(data, iv, lasso, energy, data2, alpha):\n",
    "    \n",
    "    X = data.copy()\n",
    "    y = data2[energy]\n",
    "    \n",
    "    columns = ['PERC_MAN', 'PERC_1524', 'PERC_2544',\n",
    "       'PERC_4564', 'PERC_65PL',\n",
    "       'P_NL_ACHTG,N,10,0', 'P_WE_MIG_A,N,10,0', 'PERC_MPZK',\n",
    "       'PERC_EENOUD', 'PERC_TWEEOUD', 'PERC_WON_4564',\n",
    "       'PERC_WON_6574', 'PERC_WON_7584', 'PERC_WON_8594',\n",
    "       'PERC_WON_9504', 'PERC_WON_0514', 'PERC_WON_1524',]\n",
    "    \n",
    "    X = X[columns]\n",
    "    \n",
    "    if iv == 1:\n",
    "        vis = []\n",
    "        fish = []\n",
    "\n",
    "        for i in columns:\n",
    "            for j in columns:\n",
    "                if j not in fish:\n",
    "                    vis.append([i,j])\n",
    "            fish.append(i)\n",
    "            \n",
    "        columns2 = columns.copy()\n",
    "\n",
    "        for i in vis:\n",
    "            columns2.append(i)\n",
    "            \n",
    "        for i in columns2:\n",
    "            if len(i) == 2:\n",
    "                X[i[0] + ' x ' + i[1]] = X[i[0]] * X[i[1]]\n",
    "            \n",
    "#         X = X.iloc[:, 17:]\n",
    "        \n",
    "    cols = ['PERC_MAN', 'PERC_2544', 'PERC_4564', 'P_NL_ACHTG,N,10,0',\n",
    "       'PERC_EENOUD', 'PERC_TWEEOUD', 'PERC_WON_6574', 'PERC_WON_7584',\n",
    "       'PERC_WON_8594', 'PERC_WON_9504', 'PERC_WON_0514',\n",
    "       'PERC_MAN x PERC_EENOUD', 'PERC_MAN x PERC_WON_8594',\n",
    "       'P_NL_ACHTG,N,10,0 x PERC_WON_7584',\n",
    "       'P_NL_ACHTG,N,10,0 x PERC_WON_0514', 'PERC_WON_0514 x PERC_WON_1524']\n",
    "    \n",
    "    X = X[cols]\n",
    "\n",
    "    # Prints list of random items of given length \n",
    "    list1 = set(X.index)\n",
    "\n",
    "    train = sample(list1, int(0.7 * len(list1)))\n",
    "\n",
    "    X_train = X.loc[train, :]\n",
    "    y_train = y[train]\n",
    "\n",
    "    train = set(train)\n",
    "\n",
    "    test = list1 - train\n",
    "\n",
    "    X_test = X.loc[test, :]\n",
    "    test = list(test)\n",
    "    y_test = y[test]\n",
    "        \n",
    "    if True:\n",
    "        values = [10**-3]\n",
    "        scores = []\n",
    "        scores2 = []\n",
    "\n",
    "        if True:\n",
    "            for i in values:\n",
    "                #Lasso om variabelen te bepalen\n",
    "                from sklearn import linear_model\n",
    "                clf = linear_model.ElasticNet(alpha=alpha, l1_ratio = lasso, fit_intercept=True)\n",
    "\n",
    "                clf.fit(X_train,y_train)\n",
    "\n",
    "                preds = list(clf.predict(X_test))\n",
    "                trues = list(y_test)\n",
    "\n",
    "                errors = [a_i - b_i for a_i, b_i in zip(preds, trues)]\n",
    "\n",
    "                rmse = [math.sqrt(x**2) for x in errors]\n",
    "                \n",
    "                scores2.append(sum(rmse)/len(rmse))\n",
    "                print(sum(rmse)/len(rmse))\n",
    "\n",
    "                scores.append(sum(rmse)/len(rmse))\n",
    "                \n",
    "                coef = clf.coef_\n",
    "                \n",
    "                # r-squared\n",
    "                coef = clf.coef_\n",
    "                p = numpy.poly1d(coef)\n",
    "                # fit values, and mean\n",
    "                yhat = clf.predict(X_train)\n",
    "\n",
    "                ybar = numpy.sum(y_train)/len(y_train)          # or sum(y)/len(y)\n",
    "                ssreg = numpy.sum((yhat - ybar)**2)   # or sum([ (yihat - ybar)**2 for yihat in yhat])\n",
    "                sstot = numpy.sum((y_train - ybar)**2)    # or sum([ (yi - ybar)**2 for yi in y])\n",
    "                print(ssreg / sstot)\n",
    "                \n",
    "                print(sum(clf.coef_)/len(clf.coef_))\n",
    "                print(len(clf.coef_[clf.coef_ != 0]))\n",
    "                print('--------------------------')\n",
    "\n",
    "            MSE = np.mean((y_train - clf.predict(X_train).T)**2)\n",
    "            var_est = MSE * np.diag(np.linalg.pinv(np.dot(X_train.T,X_train)))\n",
    "            SE_est = np.sqrt(var_est)\n",
    "            \n",
    "            print(clf.intercept_)\n",
    "            \n",
    "            \n",
    "            \n",
    "    return [coef, SE_est, X, scores2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef, se, X, scores2 = analyse6(data, 1, 0.3, 'G_GAS_WON,N,10,0', data2, 0.1)\n",
    "tvalues = coef / se\n",
    "\n",
    "# Find p-value\n",
    "pvalues = []\n",
    "for i in tvalues:\n",
    "    pvalues.append(scipy.stats.t.sf(abs(i), df=0.7*len(data)-len(coef)))\n",
    "\n",
    "results = pd.DataFrame(index=X.columns)\n",
    "\n",
    "results['Coefficient'] = coef\n",
    "results['Standard Error'] = se\n",
    "results['P-value'] = pvalues\n",
    "\n",
    "clean_results = results[results['Coefficient'] != 0]\n",
    "clean_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(scores2)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "plt.xscale('log')\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Alpha')\n",
    "ax1.set_ylabel('Sum of coefficient', color=color)\n",
    "ax1.plot(res[0], res[1], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:green'\n",
    "ax2.set_ylabel('RMSE', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(res[0], res[3], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('RMSE', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(res[0], res[2], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
